{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How would you define machine learning ?\n",
    "\nAns. I would say Machine Learning is a subset of Artificial Intelligence that uses computer algorithm to analyze data and make  intelligent decisions based on what it has learned, without being explicitly programmed.\n",
    "\n",
    "\n",
    "2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.\n",
    "\nAns. SUPERVISED LEARNING :\n",
    "     \nIn this technique the algorithms are trained based on labeled data.\n",
    "     \nBoth input and output data are given to the  model.\n",
    "     \nIt predicts the output and has more computational complexity.\n",
    "     \nThe main aim is to train the model so that it can predict the output when it is given new data.\n",
    "     \nIt can be categorized in Classification and Regression problems.\n",
    "     \nIt gives accurate and reliable results.\n",
    "     \nExamples-\n",
    "         \n1.Classifying whether a patient has disease or not.\n",
    "         \n2.Classifying whether an email is spam or not.\n",
    "         \n3.Predicting stock market price.\n",
    "         \n",
    "     UNSUPERVISED LEARNING:\n",
    "     In this technique the algorithms are trained based on unlabeled data.\n",
    "     Only input is given to the model.\n",
    "     It finds the hidden pattern in the data and has less computational complexity.\n",
    "     The main aim is to find the hidden patterns and useful insights from the unknown dataset.\n",
    "     It can be categorized in Clustering and Associations problems.\n",
    "     It may give less accurate and moderate reliable results.\n",
    "     Examples:\n",
    "         1.Grouping customers by purchasing behavior.\n",
    "         2.How capable an applicant is of repaying a loan from the perspective of a bank.\n",
    "         3.People that buy X also tend to buy Y.\n",
    " \n",
    " \n",
    "3) What are the test and validation set, and why would you want to use them?\n",
    "\nAns.Test Set:\n",
    "        The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "    \n",
    "    Validation Set:\n",
    "        The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model \n",
    "configuration.\n",
    "\n",
    "Validation set actually can be regarded as a part of training set, because it is used to build the model. It is usually used for parameter selection and to avoid overfitting. Test set is used for performance evaluation. Thus, Validation set is used to evaluate the performance of your model for different combinations of hyperparameter values and keep the best trained model.\n",
    "  \n",
    "\n",
    "4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
    "\nAns.Steps involved in preprocessing the data are-\n",
    "    \n",
    "    1)COLLECTING THE DATA -\n",
    "       We must first collect the relevant dataset. This dataset will be comprised of data gathered from multiple and disparate  sources which are then combined in a proper format to form a dataset. Dataset formats differ according to use cases. While collecting data, it's helpful to have a more concrete definition of quality that may include reliability, feature representation and minimising skew.\n",
    "       Reliability refers to the degree to which you can trust your data. A model trained on a reliable data set is more likely to yield useful predictions than a model trained on unreliable data.\n",
    "       Feature representation is the mapping of data to useful features.\n",
    "    \n",
    "    2)DATA CLEANING-\n",
    "        It means cleaning the data by removing outliers, replacing missing values, smoothing noisy data, and correcting inconsistent data. Many techniques are used to perform each of these tasks, where each technique is specific to user’s preference or problem set.\n",
    "        \n",
    "        For MISSING VALUES we can use following approaches-\n",
    "            \n",
    "            Removing the training example\n",
    "            Filling in missing value manually\n",
    "            Using a standard value to replace the missing value\n",
    "            Using central tendency (mean, median, mode) for attribute to replace the missing value\n",
    "            Using central tendency (mean, median, mode) for attribute belonging to same class to replace the missing value\n",
    "            Using the most probable value to fill in the missing value\n",
    "        \n",
    "        For NOISY DATA we can use following techniques-\n",
    "            \n",
    "            Binning\n",
    "            Regression\n",
    "            Outlier analysis\n",
    "            \n",
    "    3)DATA INTEGRATION-\n",
    "        Since data is being collected from multiple sources, data integration has become a vital part of the process. This may lead to redundant and inconsistent data, which could result in poor accuracy and speed of data model. To deal with these issues and maintain the data integrity, approaches such as tuple duplication detection and data conflict detection are sought after. \n",
    "        \n",
    "    4)DATA REDUCTION-\n",
    "        The purpose of data reduction is to have a condensed representation of the data set which is smaller in volume, while maintaining the integrity of original. This results in efficient yet similar results. A few methods to reduce the volume of data are:\n",
    "        Missing values ratio\n",
    "        Low variance filter\n",
    "        High correlation filter\n",
    "        Principal component analysis\n",
    "        \n",
    "    5)SPLITTING THE DATASET-\n",
    "        Every dataset for Machine Learning model must be split into two separate sets – training set and test set. Training set denotes the subset of a dataset that is used for training the machine learning model. Here, you are already aware of the output. A test set, on the other hand, is the subset of the dataset that is used for testing the machine learning model. The ML model uses the test set to predict outcomes.\n",
    "     \n",
    "    6)DATA TRANSFORMATION-\n",
    "        The final step of data preprocessing is transforming the data into form appropriate for Data Modeling. Strategies that enable data transformation include:\n",
    "        Smoothing\n",
    "        Attribute/feature construction\n",
    "        Aggregation\n",
    "        Standardization\n",
    "        Normalization\n",
    "        Discretization\n",
    "        Concept hierarchy generation for nominal data\n",
    "        \n",
    "Need for Data Preprocessing-\n",
    "    In real-world data generally contains noises, missing values, and maybe in an unusable format which cannot be directly used for machine learning models. Data preprocessing is required task as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn. Thus, we need to clean the data and make it suitable for machine learning model, this not only increases the accuracy but also the efficiency of a machine learning model is increased.\n",
    "    \n",
    "5) How you can explore continuous and discrete variables?\n",
    "\nAns. Continuous Variables- It is defined as numbers or a numeric date that can take on any value.It is a variable whose value is obtained by measuring. It represents all of the possible values in a particular interval.\n",
    "     Discrete Variables- The definition for a discrete variable is that it is countable, finite and numeric. It is a variable whose value is obtained by counting. It represents a specific and countable number of values.\n",
    "     \n",
    "     \n",
    "6) Analyze the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preprocess it.)\n",
    "\nAns. The given plot is a histogram for continuous variable. It is separated based on petal width (in cm).\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
